XOR Neural Network Experiments (PyTorch)

This project demonstrates how a small neural network can learn the XOR logic function using PyTorch.
It compares:

Different activation functions:
âœ” Sigmoid
âœ” Tanh
âœ” ReLU

Different learning rates

Different numbers of training epochs

The project also generates graphs (loss curves) to visualize how these choices affect training quality.

ðŸ“Œ What This Project Does

Builds three neural network variants for XOR

Trains them with different activation functions

Tests different learning rates (LR)

Tests different training durations (epochs)

Draws graphs showing:

How fast the model learns

How stable the learning is

Which parameters give the best results

Shows final predictions for each activation function

This is a great project for understanding the fundamentals of neural networks.
